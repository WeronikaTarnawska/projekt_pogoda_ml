{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie danych\n",
    "\n",
    "- Merge danych z różnych stacji\n",
    "- Wybór kolumn\n",
    "- Uzupełnianie braków\n",
    "- Feature engineering wspólny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "DATA_DIR = Path(\"data\")\n",
    "STATIONS = {\n",
    "    \"Wroclaw\": \"12424\",  # Cel\n",
    "    \"Legnica\": \"12415\",  # Zachód\n",
    "    \"Opole\": \"12530\",  # Wschód\n",
    "    \"Poznan\": \"12330\",  # Północ\n",
    "    \"Klodzko\": \"12520\",  # Południe\n",
    "}\n",
    "MAIN_STATION = \"Wroclaw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE=\"2018-01-01\" # Z dużymi brakami w deszczu, ale pozostałe kolumny w większości są\n",
    "# START_DATE=\"2022-05-26\" # Pełne dane deszczu\n",
    "START_DATE_FOR_RAIN_PREDICTIONS = \"2022-05-26\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane do prognozy temperatury\n",
    "\n",
    "- Uzupełnianie ewentualnych braków\n",
    "- Łączenie danych z różnych stacji\n",
    "- Podstawowy feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_MAIN = ['temp', 'rhum', 'prcp', 'snwd', 'wdir', 'wspd', 'wpgt', 'pres', 'cldc', 'coco']\n",
    "COLS_NEIGHBOR = ['temp', 'pres', 'prcp', 'wspd', 'rhum', 'wdir']\n",
    "def load_data():\n",
    "    dfs = []\n",
    "    for name, station_id in STATIONS.items():\n",
    "        file_path = DATA_DIR / f\"{name.lower()}.csv\"\n",
    "        df = pd.read_csv(file_path, parse_dates=['time'], index_col='time')\n",
    "        df = df.loc[START_DATE:]\n",
    "\n",
    "        # Select columns\n",
    "        target_cols = COLS_MAIN if name == MAIN_STATION else COLS_NEIGHBOR\n",
    "        available = [c for c in target_cols if c in df.columns]\n",
    "        df = df[available]\n",
    "\n",
    "        # Rename columns for neighbors\n",
    "        if name != MAIN_STATION:\n",
    "            df.columns = [f\"{col}_{name}\" for col in df.columns]\n",
    "        \n",
    "        dfs.append(df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_gap_report(df, freq=\"h\"):\n",
    "    idx = df.index.sort_values()\n",
    "\n",
    "    expected = pd.date_range(\n",
    "        start=idx.min(),\n",
    "        end=idx.max(),\n",
    "        freq=freq\n",
    "    )\n",
    "\n",
    "    missing = expected.difference(idx)\n",
    "\n",
    "    # długości dziur\n",
    "    diffs = idx.to_series().diff()\n",
    "    step = pd.to_timedelta(1, unit=freq)\n",
    "\n",
    "    gap_sizes = diffs[diffs > step]\n",
    "\n",
    "    if len(gap_sizes) == 0:\n",
    "        max_gap = pd.Timedelta(0)\n",
    "    else:\n",
    "        max_gap = gap_sizes.max()\n",
    "\n",
    "    print(f\"  missing timestamps: {len(missing)}\")\n",
    "    print(f\"  longest gap: {max_gap}\")\n",
    "\n",
    "    return missing, gap_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  missing timestamps: 2\n",
      "  longest gap: 0 days 03:00:00\n",
      "  missing timestamps: 16\n",
      "  longest gap: 0 days 03:00:00\n",
      "  missing timestamps: 8\n",
      "  longest gap: 0 days 03:00:00\n",
      "  missing timestamps: 3\n",
      "  longest gap: 0 days 03:00:00\n",
      "  missing timestamps: 8\n",
      "  longest gap: 0 days 03:00:00\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "  index_gap_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_continuous_index(df, freq=\"h\"):\n",
    "    full_idx = pd.date_range(\n",
    "        start=df.index.min(),\n",
    "        end=df.index.max(),\n",
    "        freq=freq\n",
    "    )\n",
    "    return df.reindex(full_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n",
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n",
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n",
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n",
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dfs_new = []\n",
    "for df in dfs:\n",
    "  dfs_new.append(enforce_continuous_index(df))\n",
    "dfs=dfs_new\n",
    "for df in dfs:\n",
    "  index_gap_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp     0.002853\n",
      "rhum     0.004279\n",
      "prcp    55.700735\n",
      "snwd    99.736110\n",
      "wdir     0.029955\n",
      "wspd     0.002853\n",
      "wpgt     7.233436\n",
      "pres     0.004279\n",
      "cldc     3.126738\n",
      "coco     4.484702\n",
      "dtype: float64\n",
      "temp_Legnica     0.022823\n",
      "pres_Legnica     0.022823\n",
      "prcp_Legnica    55.700735\n",
      "wspd_Legnica     0.155481\n",
      "rhum_Legnica     0.022823\n",
      "wdir_Legnica     0.022823\n",
      "dtype: float64\n",
      "temp_Opole     0.011411\n",
      "pres_Opole     0.011411\n",
      "prcp_Opole    55.700735\n",
      "wspd_Opole     0.128379\n",
      "rhum_Opole     0.011411\n",
      "wdir_Opole     0.011411\n",
      "dtype: float64\n",
      "temp_Poznan     0.004279\n",
      "pres_Poznan     0.005706\n",
      "prcp_Poznan    55.700735\n",
      "wspd_Poznan     0.004279\n",
      "rhum_Poznan     0.044219\n",
      "wdir_Poznan     0.005706\n",
      "dtype: float64\n",
      "temp_Klodzko     0.011411\n",
      "pres_Klodzko     0.011411\n",
      "prcp_Klodzko    55.700735\n",
      "wspd_Klodzko     0.232508\n",
      "rhum_Klodzko     0.011411\n",
      "wdir_Klodzko     0.159760\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zasady uzupełniania:\n",
    "\n",
    "- **temp** - jak godzinę temu\n",
    "- **rhum** - jak godzinę temu\n",
    "- **prcp** - 0\n",
    "- **snwd** - 0\n",
    "- **wdir** - jak godzinę temu\n",
    "- **wspd** - jak godzinę temu\n",
    "- **wpgt** - jak **wspd**\n",
    "- **pres** - jak godzinę temu\n",
    "- **tsun** - usuń całą kolumnę (zrobione wcześniej)\n",
    "- **cldc** - jak godzinę temu\n",
    "- **coco** - jak godzinę temu, a braki na początku danych 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # reguły bazowe (bez sufiksów)\n",
    "    ffill_cols = ['temp', 'rhum', 'wdir', 'wspd', 'pres', 'cldc', 'coco']\n",
    "    zero_cols = ['prcp', 'snwd', 'coco']\n",
    "\n",
    "    # 1. zerowanie opadu i śniegu\n",
    "    for base in zero_cols:\n",
    "        cols = [c for c in df.columns if c == base or c.startswith(f\"{base}_\")]\n",
    "        df[cols] = df[cols].fillna(0)\n",
    "\n",
    "    # 2. forward fill zmiennych wolnozmiennych\n",
    "    for base in ffill_cols:\n",
    "        cols = [c for c in df.columns if c == base or c.startswith(f\"{base}_\")]\n",
    "        df[cols] = df[cols].ffill()\n",
    "\n",
    "    # 3. wpgt = jak wspd\n",
    "    # stacja główna\n",
    "    if 'wpgt' in df.columns and 'wspd' in df.columns:\n",
    "        df['wpgt'] = df['wpgt'].fillna(df['wspd'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp    0.0\n",
      "rhum    0.0\n",
      "prcp    0.0\n",
      "snwd    0.0\n",
      "wdir    0.0\n",
      "wspd    0.0\n",
      "wpgt    0.0\n",
      "pres    0.0\n",
      "cldc    0.0\n",
      "coco    0.0\n",
      "dtype: float64\n",
      "temp_Legnica    0.0\n",
      "pres_Legnica    0.0\n",
      "prcp_Legnica    0.0\n",
      "wspd_Legnica    0.0\n",
      "rhum_Legnica    0.0\n",
      "wdir_Legnica    0.0\n",
      "dtype: float64\n",
      "temp_Opole    0.0\n",
      "pres_Opole    0.0\n",
      "prcp_Opole    0.0\n",
      "wspd_Opole    0.0\n",
      "rhum_Opole    0.0\n",
      "wdir_Opole    0.0\n",
      "dtype: float64\n",
      "temp_Poznan    0.0\n",
      "pres_Poznan    0.0\n",
      "prcp_Poznan    0.0\n",
      "wspd_Poznan    0.0\n",
      "rhum_Poznan    0.0\n",
      "wdir_Poznan    0.0\n",
      "dtype: float64\n",
      "temp_Klodzko    0.0\n",
      "pres_Klodzko    0.0\n",
      "prcp_Klodzko    0.0\n",
      "wspd_Klodzko    0.0\n",
      "rhum_Klodzko    0.0\n",
      "wdir_Klodzko    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dfs_new = []\n",
    "for df in dfs:\n",
    "  dfs_new.append(fill_missing_values(df))\n",
    "dfs=dfs_new\n",
    "for df in dfs:\n",
    "    print(df.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp            0.0\n",
      "rhum            0.0\n",
      "prcp            0.0\n",
      "snwd            0.0\n",
      "wdir            0.0\n",
      "wspd            0.0\n",
      "wpgt            0.0\n",
      "pres            0.0\n",
      "cldc            0.0\n",
      "coco            0.0\n",
      "temp_Legnica    0.0\n",
      "pres_Legnica    0.0\n",
      "prcp_Legnica    0.0\n",
      "wspd_Legnica    0.0\n",
      "rhum_Legnica    0.0\n",
      "wdir_Legnica    0.0\n",
      "temp_Opole      0.0\n",
      "pres_Opole      0.0\n",
      "prcp_Opole      0.0\n",
      "wspd_Opole      0.0\n",
      "rhum_Opole      0.0\n",
      "wdir_Opole      0.0\n",
      "temp_Poznan     0.0\n",
      "pres_Poznan     0.0\n",
      "prcp_Poznan     0.0\n",
      "wspd_Poznan     0.0\n",
      "rhum_Poznan     0.0\n",
      "wdir_Poznan     0.0\n",
      "temp_Klodzko    0.0\n",
      "pres_Klodzko    0.0\n",
      "prcp_Klodzko    0.0\n",
      "wspd_Klodzko    0.0\n",
      "rhum_Klodzko    0.0\n",
      "wdir_Klodzko    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Merge all stations on time index\n",
    "df_combined = pd.concat(dfs, axis=1).sort_index()\n",
    "df_combined.dropna()\n",
    "print(df_combined.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  missing timestamps: 0\n",
      "  longest gap: 0 days 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex([], dtype='datetime64[ns]', freq='h'),\n",
       " Series([], Freq: h, dtype: timedelta64[ns]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_gap_report(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    idx = df.index\n",
    "    df['year'] = idx.year\n",
    "    df['month'] = idx.month\n",
    "    df['day'] = idx.day\n",
    "    df['day_of_year'] = idx.dayofyear\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snwd</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>cldc</th>\n",
       "      <th>coco</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_Klodzko</th>\n",
       "      <th>pres_Klodzko</th>\n",
       "      <th>prcp_Klodzko</th>\n",
       "      <th>wspd_Klodzko</th>\n",
       "      <th>rhum_Klodzko</th>\n",
       "      <th>wdir_Klodzko</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>10.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1004.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>81.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>10.1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1004.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>9.8</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1003.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1006.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>10.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>10.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1003.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1006.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temp  rhum  prcp  snwd   wdir  wspd  wpgt    pres  cldc  \\\n",
       "2018-01-01 00:00:00  10.1  72.0   0.0   0.0  220.0  18.0  18.0  1004.3   7.0   \n",
       "2018-01-01 01:00:00  10.1  71.0   0.0   0.0  220.0  18.0  18.0  1004.1   7.0   \n",
       "2018-01-01 02:00:00   9.8  71.0   0.0   0.0  220.0  14.4  14.4  1003.9   7.0   \n",
       "2018-01-01 03:00:00  10.1  69.0   0.0   0.0  230.0  21.6  21.6  1003.6   7.0   \n",
       "2018-01-01 04:00:00  10.3  68.0   0.0   0.0  220.0  21.6  21.6  1003.1   7.0   \n",
       "\n",
       "                     coco  ...  temp_Klodzko  pres_Klodzko  prcp_Klodzko  \\\n",
       "2018-01-01 00:00:00   0.0  ...           7.0        1006.9           0.0   \n",
       "2018-01-01 01:00:00   0.0  ...           6.6        1006.9           0.0   \n",
       "2018-01-01 02:00:00   0.0  ...           7.3        1006.2           0.0   \n",
       "2018-01-01 03:00:00   0.0  ...           6.3        1006.0           0.0   \n",
       "2018-01-01 04:00:00   0.0  ...           6.2        1006.1           0.0   \n",
       "\n",
       "                     wspd_Klodzko  rhum_Klodzko  wdir_Klodzko  year  month  \\\n",
       "2018-01-01 00:00:00          10.8          81.0         230.0  2018      1   \n",
       "2018-01-01 01:00:00           7.2          80.0         230.0  2018      1   \n",
       "2018-01-01 02:00:00          10.8          77.0         200.0  2018      1   \n",
       "2018-01-01 03:00:00          18.0          79.0         170.0  2018      1   \n",
       "2018-01-01 04:00:00          18.0          82.0         190.0  2018      1   \n",
       "\n",
       "                     day  day_of_year  \n",
       "2018-01-01 00:00:00    1            1  \n",
       "2018-01-01 01:00:00    1            1  \n",
       "2018-01-01 02:00:00    1            1  \n",
       "2018-01-01 03:00:00    1            1  \n",
       "2018-01-01 04:00:00    1            1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_engineering(df_combined)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR / \"combined.csv\", index_label=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[START_DATE_FOR_RAIN_PREDICTIONS:]\n",
    "df.to_csv(DATA_DIR / \"combined_rain.csv\", index_label=\"time\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
